{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8e06c6a-dd57-490e-86d4-1c4499862a21",
   "metadata": {},
   "source": [
    "# Analyze Speech & Language with Google API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f237f019-178c-41c9-9f02-7f50b58bbeb1",
   "metadata": {},
   "source": [
    "## Task 1. Create an API key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf36b8b-405b-4150-9e18-e6fe697645d3",
   "metadata": {},
   "source": [
    "Generate an API user key to pass in the request URL.\n",
    "\n",
    "1. To create an API key, select **Navigation menu > APIs & Services > Credentials**.\n",
    "\n",
    "2. Click **Create credentials** at the top and select **API key**:\n",
    "\n",
    "3. Copy the API key to a text file to use in a later step. Click **Close**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c91b2a-a6fc-49d4-bfed-a4d2e93bcfe1",
   "metadata": {},
   "source": [
    "## Task 2. Make an entity analysis request and call the Natural Language API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c74c37-b328-41d1-a228-7b7c3f145bc7",
   "metadata": {},
   "source": [
    "1. Click **Navigation menu > Compute Engine** to connect via SSH to the VM instance.\n",
    "\n",
    "2. Click on the **SSH** button.\n",
    "\n",
    "3. In the command line, enter in the following:\n",
    "   export API_KEY=<YOUR_API_KEY?>\n",
    "\n",
    "4. Create a JSON file using the code that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d1d696-b174-4e08-936a-46c6cbf092cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat > nl_request.json <<EOF\n",
    "{\n",
    "  \"document\":{\n",
    "    \"type\":\"PLAIN_TEXT\",\n",
    "    \"content\":\"With approximately 8.2 million people residing in Boston, the capital city of Massachusetts is one of the largest in the United States.\"\n",
    "  },\n",
    "  \"encodingType\":\"UTF8\"\n",
    "}\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a265c6e-f801-498c-87f8-9a34e071d278",
   "metadata": {},
   "source": [
    "5. Pass the following request to the **Natural Language API** using the **curl** command, and save the response in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b086a8-a5ad-41e2-bd23-f40b64277753",
   "metadata": {},
   "outputs": [],
   "source": [
    "curl \"https://language.googleapis.com/v1/documents:analyzeEntities?key=${API_KEY}\" \\\n",
    "  -s -X POST -H \"Content-Type: application/json\" --data-binary @nl_request.json > nl_response.json\n",
    "\n",
    "cat nl_response.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c434a9ac-d719-4cf1-b4aa-32f3d865cb95",
   "metadata": {},
   "source": [
    "## Task 3. Create a speech analysis request and call the Speech API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a31dfd-b643-485e-bfcd-085479e0788c",
   "metadata": {},
   "source": [
    "1. Create a JSON file using the code that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafba57c-cbf0-44ad-8a18-b21baa223b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat > speech_request.json <<EOF\n",
    "{\n",
    "  \"config\": {\n",
    "      \"encoding\":\"FLAC\",\n",
    "      \"languageCode\": \"en-US\"\n",
    "  },\n",
    "  \"audio\": {\n",
    "      \"uri\":\"gs://cloud-samples-tests/speech/brooklyn.flac\"\n",
    "  }\n",
    "}\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69ce9df-ec62-48a2-9565-b56da229c0e8",
   "metadata": {},
   "source": [
    "2. Pass the following request to the **Natural Language API** using the **curl** command, and save the response in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72170e41-8a89-476a-8db3-7acabf035451",
   "metadata": {},
   "outputs": [],
   "source": [
    "curl -s -X POST -H \"Content-Type: application/json\" --data-binary @speech_request.json \\\n",
    "\"https://speech.googleapis.com/v1/speech:recognize?key=${API_KEY}\" > speech_response.json\n",
    "\n",
    "cat speech_response.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622dafdf-92bd-498d-9cf9-2ae4d9a57032",
   "metadata": {},
   "source": [
    "## Task 4. Analyze sentiment with the Natural Language API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e60ce93-bf4a-4b3f-a309-291f1902de29",
   "metadata": {},
   "source": [
    "1. Create a py file using the code that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394eb994-f6ab-4763-83ef-1306ffa84f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat > sentiment_analysis.py <<EOF\n",
    "import argparse\n",
    "\n",
    "from google.cloud import language_v1\n",
    "\n",
    "def print_result(annotations):\n",
    "    score = annotations.document_sentiment.score\n",
    "    magnitude = annotations.document_sentiment.magnitude\n",
    "\n",
    "    for index, sentence in enumerate(annotations.sentences):\n",
    "        sentence_sentiment = sentence.sentiment.score\n",
    "        print(\n",
    "            \"Sentence {} has a sentiment score of {}\".format(index, sentence_sentiment)\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        \"Overall Sentiment: score of {} with magnitude of {}\".format(score, magnitude)\n",
    "    )\n",
    "    return 0\n",
    "\n",
    "def analyze(movie_review_filename):\n",
    "    \"\"\"Run a sentiment analysis request on text within a passed filename.\"\"\"\n",
    "    # Instantiate a LanguageServiceClient instance as the client.\n",
    "    client = language_v1.LanguageServiceClient()\n",
    "\n",
    "    # Read the filename containing the text data into a variable.\n",
    "    with open(movie_review_filename) as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Instantiate a Document object with the contents of the file.\n",
    "    document = language_v1.Document(content=content,\n",
    "        type_=language_v1.Document.Type.PLAIN_TEXT)\n",
    "\n",
    "    # Call the client's analyze_sentiment method.\n",
    "    annotations = client.analyze_sentiment(request={\"document\": document})\n",
    "\n",
    "    # Print the results\n",
    "    print_result(annotations)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"movie_review_filename\",\n",
    "        help=\"The filename of the movie review you'd like to analyze.\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    analyze(args.movie_review_filename)\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b55a28-b664-40d6-93ca-f05faf93c292",
   "metadata": {},
   "source": [
    "2. Run the sentiment analysis on the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad8f756-83f8-4d29-9460-15bd8cd149cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsutil cp gs://cloud-samples-tests/natural-language/sentiment-samples.tgz .\n",
    "\n",
    "gunzip sentiment-samples.tgz\n",
    "tar -xvf sentiment-samples.tar\n",
    "python3 sentiment_analysis.py reviews/bladerunner-pos.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
