{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UiNxsd4_q9wq"
   },
   "source": [
    "### What-If Tool Image Smile Detection\n",
    "\n",
    "In this demo we demonstrate the use of what-if-tool for image recognition models. Our task is to predict if a person is smiling or not. We provide a CNN that is trained on a subset of [CelebA dataset](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) and visualize the results on a separate test subset.\n",
    "\n",
    "Copyright 2019 Google LLC.\n",
    "SPDX-License-Identifier: Apache-2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the right version of Tensorflow is installed.\n",
    "!pip freeze | grep tensorflow==2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Re-run** the below cell until you see the output `Successfully installed h5py-2.10.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: h5py 3.1.0\n",
      "Uninstalling h5py-3.1.0:\n",
      "  Successfully uninstalled h5py-3.1.0\n",
      "Collecting h5py<3.0.0\n",
      "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
      "     |████████████████████████████████| 2.9 MB 5.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /opt/conda/lib/python3.7/site-packages (from h5py<3.0.0) (1.19.5)\n",
      "Requirement already satisfied: six in /home/jupyter/.local/lib/python3.7/site-packages (from h5py<3.0.0) (1.15.0)\n",
      "Installing collected packages: h5py\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\n",
      "explainable-ai-sdk 1.3.2 requires xai-image-widget, which is not installed.\n",
      "tensorflow 2.6.2 requires h5py~=3.1.0, but you have h5py 2.10.0 which is incompatible.\n",
      "tensorflow-transform 1.4.0 requires absl-py<0.13,>=0.9, but you have absl-py 0.15.0 which is incompatible.\n",
      "tensorflow-transform 1.4.0 requires pyarrow<6,>=1, but you have pyarrow 6.0.1 which is incompatible.\n",
      "tensorflow-transform 1.4.0 requires tensorflow-metadata<1.5.0,>=1.4.0, but you have tensorflow-metadata 1.5.0 which is incompatible.\u001b[0m\n",
      "Successfully installed h5py-2.10.0\n"
     ]
    }
   ],
   "source": [
    "# Install version 2.10 of h5py\n",
    "import sys\n",
    "!{sys.executable} -m pip uninstall -y h5py\n",
    "!{sys.executable} -m pip install 'h5py < 3.0.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Note**: Please ignore any **incompatibility ERROR** that may appear for the packages visions as it will not affect the lab's functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to use the correct __h5py__ version, you will need to restart the notebook's kernel. To do this, select __Kernel__ > __Restart Kernel__ from the top menu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the pretrained keras model files and subset of celeba images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "EBOHfrOP7Iy5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 39.6M  100 39.6M    0     0   187M      0 --:--:-- --:--:-- --:--:--  187M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 3819k  100 3819k    0     0   155M      0 --:--:-- --:--:-- --:--:--  155M\n"
     ]
    }
   ],
   "source": [
    "!curl -L https://storage.googleapis.com/what-if-tool-resources/smile-demo/smile-colab-model.hdf5 -o ./smile-model.hdf5\n",
    "!curl -L https://storage.googleapis.com/what-if-tool-resources/smile-demo/test_subset.zip -o ./test_subset.zip\n",
    "!unzip -qq -o test_subset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define helper functions for dataset conversion from csv to tf.Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "4H2nX-2dEgsR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# Converts a dataframe into a list of tf.Example protos.\n",
    "# If images_path is specified, it assumes that the dataframe has a special \n",
    "# column \"image_id\" and the path \"images_path/image_id\" points to an image file.\n",
    "# Given this structure, this function loads and processes the images as png byte_lists\n",
    "# into tf.Examples so that they can be shown in WIT. Note that 'image/encoded'\n",
    "# is a reserved field in WIT for encoded image features.\n",
    "def df_to_examples(df, columns=None, images_path=''):\n",
    "    examples = []\n",
    "    if columns == None:\n",
    "        columns = df.columns.values.tolist()\n",
    "    for index, row in df.iterrows():\n",
    "        example = tf.train.Example()\n",
    "        for col in columns:\n",
    "            if df[col].dtype is np.dtype(np.int64):\n",
    "                example.features.feature[col].int64_list.value.append(int(row[col]))\n",
    "            elif df[col].dtype is np.dtype(np.float64):\n",
    "                example.features.feature[col].float_list.value.append(row[col])\n",
    "            elif row[col] == row[col]:\n",
    "                example.features.feature[col].bytes_list.value.append(row[col].encode('utf-8'))\n",
    "        if images_path:\n",
    "            fname = row['image_id']\n",
    "            with open(os.path.join(images_path, fname), 'rb') as f:\n",
    "                im = Image.open(f)\n",
    "                buf = BytesIO()\n",
    "                im.save(buf, format= 'PNG')\n",
    "                im_bytes = buf.getvalue()\n",
    "                example.features.feature['image/encoded'].bytes_list.value.append(im_bytes)\n",
    "        examples.append(example)\n",
    "    return examples\n",
    "\n",
    "# Converts a dataframe column into a column of 0's and 1's based on the provided test.\n",
    "# Used to force label columns to be numeric for binary classification using a TF estimator.\n",
    "def make_label_column_numeric(df, label_column, test):\n",
    "    df[label_column] = np.where(test(df[label_column]), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the csv file into pandas dataframe and process it for WIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "MGpLKJI_HY9m"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('celeba/data_test_subset.csv')\n",
    "examples = df_to_examples(data, images_path='celeba/img_test_subset_resized/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "zZR3i6UZlZ96"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 00:19:58.222237: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model1 = load_model('smile-model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the custom predict function for WIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "E5fYynA9ZpPJ"
   },
   "outputs": [],
   "source": [
    "# This function extracts 'image/encoded' field, which is a reserved key for the \n",
    "# feature that contains encoded image byte list. We read this feature into \n",
    "# BytesIO and decode it back to an image using PIL.\n",
    "# The model expects an array of images that are floats in range 0.0 to 1.0 and \n",
    "# outputs a numpy array of (n_samples, n_labels)\n",
    "def custom_predict(examples_to_infer):\n",
    "    def load_byte_img(im_bytes):\n",
    "        buf = BytesIO(im_bytes)\n",
    "        return np.array(Image.open(buf), dtype=np.float64) / 255.\n",
    "\n",
    "    ims = [load_byte_img(ex.features.feature['image/encoded'].bytes_list.value[0]) \n",
    "        for ex in examples_to_infer]\n",
    "    preds = model1.predict(np.array(ims))\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ldvP-msGPnIv"
   },
   "source": [
    "## Note that this particular model only uses images as input. Therefore, partial dependence plots are flat for all features. These features are provided for slicing and analysis purposes.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoke What-If Tool for the data and model {display-mode: \"form\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UwiWGrLlSWGh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 00:20:15.414748: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a14434181d6b4d42a4bed578e5a590a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WitWidget(config={'model_type': 'classification', 'label_vocab': [], 'are_sequence_examples': False, 'inferenc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from witwidget.notebook.visualization import WitWidget, WitConfigBuilder, display\n",
    "\n",
    "num_datapoints = 250 \n",
    "tool_height_in_px = 700\n",
    "\n",
    "# Decode an image from tf.example bytestring\n",
    "def decode_image(ex):\n",
    "    im_bytes = ex.features.feature['image/encoded'].bytes_list.value[0]\n",
    "    im = Image.open(BytesIO(im_bytes))\n",
    "    return im\n",
    "\n",
    "# Define the custom distance function that compares the average color of images\n",
    "def image_mean_distance(ex, exs, params):\n",
    "    selected_im = decode_image(ex)\n",
    "    mean_color = np.mean(selected_im, axis=(0,1))\n",
    "    image_distances = [np.linalg.norm(mean_color - np.mean(decode_image(e), axis=(0,1))) for e in exs]\n",
    "    return image_distances\n",
    "\n",
    "# Setup the tool with the test examples and the trained classifier\n",
    "config_builder = WitConfigBuilder(examples[:num_datapoints]).set_custom_predict_fn(\n",
    "    custom_predict).set_custom_distance_fn(image_mean_distance)\n",
    "\n",
    "wv = WitWidget(config_builder, height=tool_height_in_px)\n",
    "display(wv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A1s1_SiOyS0l"
   },
   "source": [
    "#### Exploration ideas\n",
    "\n",
    "- In the \"Performance\" tab, set the ground truth feature to \"Smiling\". You can set a scatter axis or binning option to be inference correct and analyze how it varies across other features (i.e. you can make a scatter plot of Young vs inference correct).\n",
    "- Choose an image and click on \"Show nearest counterfactual datapoint\", this will find another example that is closest to the selected image in terms of average color value, but has a different prediction (if selected image is predicted to be \"smiling\" the counterfactual one will have \"not smiling\" prediction).\n",
    "- Define your own custom distance function and set it by calling set_custom_distance_fn on config_builder and explore the counterfactuals. You can even load another neural network to compute distances!\n",
    "- You can slice by any one of the features and analyze the confusion matrix and accuracy for each group.\n",
    "- In the \"Datapoint Editor\" tab, you can upload your own image or download and modify one of the images to see how it affects the inference score.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "WIT_Smile_Detector.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m87"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
