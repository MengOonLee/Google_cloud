{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca0c5353-166f-4dc1-8c48-c253b74aa187",
   "metadata": {},
   "source": [
    "# Rental recommendation using Cloud SQL and Spark\n",
    "\n",
    "Train the recommendations machine learning model based on user's previous ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ed384b-b4d5-43ac-8089-d9e182c260a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MySQL database\n",
    "CREATE DATABASE IF NOT EXISTS recommendation_spark;\n",
    "USE recommendation_spark;\n",
    "DROP TABLE IF EXISTS Recommendation;\n",
    "DROP TABLE IF EXISTS Rating;\n",
    "DROP TABLE IF EXISTS Accommodation;\n",
    "CREATE TABLE IF NOT EXISTS Accommodation\n",
    "(\n",
    "  id varchar(255),\n",
    "  title varchar(255),\n",
    "  location varchar(255),\n",
    "  price int,\n",
    "  rooms int,\n",
    "  rating float,\n",
    "  type varchar(255),\n",
    "  PRIMARY KEY (ID)\n",
    ");\n",
    "CREATE TABLE  IF NOT EXISTS Rating\n",
    "(\n",
    "  userId varchar(255),\n",
    "  accoId varchar(255),\n",
    "  rating int,\n",
    "  PRIMARY KEY(accoId, userId),\n",
    "  FOREIGN KEY (accoId)\n",
    "  REFERENCES Accommodation(id)\n",
    ");\n",
    "CREATE TABLE  IF NOT EXISTS Recommendation\n",
    "(\n",
    "  userId varchar(255),\n",
    "  accoId varchar(255),\n",
    "  prediction float,\n",
    "  PRIMARY KEY(userId, accoId),\n",
    "  FOREIGN KEY (accoId)\n",
    "  REFERENCES Accommodation(id)\n",
    ");\n",
    "SHOW DATABASES;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69cadd2-aae8-4253-9857-416ea6c4d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to database\n",
    "gcloud sql connect rentals --user=root --quiet\n",
    "\n",
    "SHOW DATABASES;\n",
    "\n",
    "USE recommendation_spark;\n",
    "SHOW TABLES;\n",
    "SELECT * FROM Accommodation;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d64e340-3873-4620-a37e-ab32436dabd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage data in Cloud Storage\n",
    "echo \"Creating bucket: gs://$DEVSHELL_PROJECT_ID\"\n",
    "gsutil mb gs://$DEVSHELL_PROJECT_ID\n",
    "echo \"Copying data to our storage from public dataset\"\n",
    "gsutil cp gs://cloud-training/bdml/v2.0/data/accommodation.csv gs://$DEVSHELL_PROJECT_ID\n",
    "gsutil cp gs://cloud-training/bdml/v2.0/data/rating.csv gs://$DEVSHELL_PROJECT_ID\n",
    "echo \"Show the files in our bucket\"\n",
    "gsutil ls gs://$DEVSHELL_PROJECT_ID\n",
    "echo \"View some sample data\"\n",
    "gsutil cat gs://$DEVSHELL_PROJECT_ID/accommodation.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ab9e1a-a81a-4416-8f61-34296d44282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Cloud SQL data\n",
    "USE recommendation_spark;\n",
    "SELECT * FROM Rating\n",
    "LIMIT 15;\n",
    "\n",
    "# SQL aggregation to count the number of rows\n",
    "SELECT COUNT(*) AS num_ratings\n",
    "FROM Rating;\n",
    "\n",
    "# Average review rating of accommodations\n",
    "SELECT\n",
    "    COUNT(userId) AS num_ratings,\n",
    "    COUNT(DISTINCT userId) AS distinct_user_ratings,\n",
    "    MIN(rating) AS worst_rating,\n",
    "    MAX(rating) AS best_rating,\n",
    "    AVG(rating) AS avg_rating\n",
    "FROM Rating;\n",
    "\n",
    "# Which users have provided the most ratings\n",
    "SELECT\n",
    "    userId,\n",
    "    COUNT(rating) AS num_ratings\n",
    "FROM Rating\n",
    "GROUP BY userId\n",
    "ORDER BY num_ratings DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d3c91b-188b-4d2f-9f11-66f95c71e5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patching Cloud SQL instance\n",
    "echo \"Authorizing Cloud Dataproc to connect with Cloud SQL\"\n",
    "CLUSTER=rentals\n",
    "CLOUDSQL=rentals\n",
    "ZONE=us-central1-c\n",
    "NWORKERS=2\n",
    "machines=\"$CLUSTER-m\"\n",
    "for w in `seq 0 $(($NWORKERS - 1))`; do\n",
    "   machines=\"$machines $CLUSTER-w-$w\"\n",
    "done\n",
    "echo \"Machines to authorize: $machines in $ZONE ... finding their IP addresses\"\n",
    "ips=\"\"\n",
    "for machine in $machines; do\n",
    "    IP_ADDRESS=$(gcloud compute instances describe $machine --zone=$ZONE --format='value(networkInterfaces.accessConfigs[].natIP)' | sed \"s/\\['//g\" | sed \"s/'\\]//g\" )/32\n",
    "    echo \"IP address of $machine is $IP_ADDRESS\"\n",
    "    if [ -z  $ips ]; then\n",
    "       ips=$IP_ADDRESS\n",
    "    else\n",
    "       ips=\"$ips,$IP_ADDRESS\"\n",
    "    fi\n",
    "done\n",
    "echo \"Authorizing [$ips] to access cloudsql=$CLOUDSQL\"\n",
    "gcloud sql instances patch $CLOUDSQL --authorized-networks $ips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eac4f11-7beb-442b-b574-033d7d60fd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile train_and_apply.py\n",
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Copyright Google Inc. 2016\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import itertools\n",
    "from math import sqrt\n",
    "from operator import add\n",
    "from os.path import join, isfile, dirname\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType\n",
    "\n",
    "# MAKE EDITS HERE\n",
    "CLOUDSQL_INSTANCE_IP = '35.224.45.106'   # <---- CHANGE (database server IP)\n",
    "CLOUDSQL_DB_NAME = 'recommendation_spark' # <--- leave as-is\n",
    "CLOUDSQL_USER = 'root'  # <--- leave as-is\n",
    "CLOUDSQL_PWD  = 'mTV2sqx64Rrr'  # <---- CHANGE\n",
    "\n",
    "# DO NOT MAKE EDITS BELOW\n",
    "conf = SparkConf().setAppName(\"train_model\")\n",
    "sc = SparkContext(conf=conf)\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "jdbcDriver = 'com.mysql.jdbc.Driver'\n",
    "jdbcUrl    = 'jdbc:mysql://%s:3306/%s?user=%s&password=%s' % (CLOUDSQL_INSTANCE_IP, CLOUDSQL_DB_NAME, CLOUDSQL_USER, CLOUDSQL_PWD)\n",
    "\n",
    "# checkpointing helps prevent stack overflow errors\n",
    "sc.setCheckpointDir('checkpoint/')\n",
    "\n",
    "# Read the ratings and accommodations data from Cloud SQL\n",
    "dfRates = sqlContext.read.format('jdbc').options(driver=jdbcDriver, url=jdbcUrl, dbtable='Rating', useSSL='false').load()\n",
    "dfAccos = sqlContext.read.format('jdbc').options(driver=jdbcDriver, url=jdbcUrl, dbtable='Accommodation', useSSL='false').load()\n",
    "print(\"read ...\")\n",
    "\n",
    "# train the model\n",
    "model = ALS.train(dfRates.rdd, 20, 20) # you could tune these numbers, but these are reasonable choices\n",
    "print(\"trained ...\")\n",
    "\n",
    "# use this model to predict what the user would rate accommodations that she has not rated\n",
    "allPredictions = None\n",
    "for USER_ID in range(0, 100):\n",
    "  dfUserRatings = dfRates.filter(dfRates.userId == USER_ID).rdd.map(lambda r: r.accoId).collect()\n",
    "  rddPotential  = dfAccos.rdd.filter(lambda x: x[0] not in dfUserRatings)\n",
    "  pairsPotential = rddPotential.map(lambda x: (USER_ID, x[0]))\n",
    "  predictions = model.predictAll(pairsPotential).map(lambda p: (str(p[0]), str(p[1]), float(p[2])))\n",
    "  predictions = predictions.takeOrdered(5, key=lambda x: -x[2]) # top 5\n",
    "  print(\"predicted for user={0}\".format(USER_ID))\n",
    "  if (allPredictions == None):\n",
    "    allPredictions = predictions\n",
    "  else:\n",
    "    allPredictions.extend(predictions)\n",
    "\n",
    "# write them\n",
    "schema = StructType([StructField(\"userId\", StringType(), True), StructField(\"accoId\", StringType(), True), StructField(\"prediction\", FloatType(), True)])\n",
    "dfToSave = sqlContext.createDataFrame(allPredictions, schema)\n",
    "dfToSave.write.jdbc(url=jdbcUrl, table='Recommendation', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b822a4-bdef-4aad-9181-58bcc76e9814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the ML model\n",
    "gsutil cp gs://cloud-training/bdml/v2.0/model/train_and_apply.py train_and_apply.py\n",
    "cloudshell edit train_and_apply.py\n",
    "\n",
    "gsutil cp train_and_apply.py gs://$DEVSHELL_PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d202b0d1-3754-49de-902a-322612620861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore inserted rows\n",
    "\n",
    "USE recommendation_spark;\n",
    "SELECT COUNT(*) AS count FROM Recommendation;\n",
    "\n",
    "# Find the recommendations for a user\n",
    "SELECT\n",
    "    r.userid,\n",
    "    r.accoid,\n",
    "    r.prediction,\n",
    "    a.title,\n",
    "    a.location,\n",
    "    a.price,\n",
    "    a.rooms,\n",
    "    a.rating,\n",
    "    a.type\n",
    "FROM Recommendation as r\n",
    "JOIN Accommodation as a\n",
    "ON r.accoid = a.id\n",
    "WHERE r.userid = 10;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
